{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecb2d0b1-992b-43ad-b57c-8779b7a83321",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-03T00:31:40.275720Z",
     "iopub.status.busy": "2024-02-03T00:31:40.274986Z",
     "iopub.status.idle": "2024-02-03T00:31:47.271214Z",
     "shell.execute_reply": "2024-02-03T00:31:47.270448Z",
     "shell.execute_reply.started": "2024-02-03T00:31:40.275681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six in /usr/lib/python3/dist-packages (from langdetect) (1.14.0)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=97cd4a3ce871a6a0c0550184f2893834fb5befd341a01455f1d844aed8e50dea\n",
      "  Stored in directory: /root/.cache/pip/wheels/6a/67/f8/9cf1a8ff87e0b37f738769df49cc142a655489a6d27b68089f\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect\n",
      "Successfully installed langdetect-1.0.9\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting fastai\n",
      "  Downloading fastai-2.7.14-py3-none-any.whl (232 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.2/232.2 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.9/dist-packages (from fastai) (9.2.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from fastai) (1.1.2)\n",
      "Requirement already satisfied: torch<2.3,>=1.10 in /usr/local/lib/python3.9/dist-packages (from fastai) (1.12.1+cu116)\n",
      "Collecting fastdownload<2,>=0.0.5\n",
      "  Downloading fastdownload-0.0.7-py3-none-any.whl (12 kB)\n",
      "Collecting fastprogress>=0.2.4\n",
      "  Downloading fastprogress-1.0.3-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from fastai) (2.28.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from fastai) (1.5.0)\n",
      "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.9/dist-packages (from fastai) (3.4.1)\n",
      "Collecting fastcore<1.6,>=1.5.29\n",
      "  Downloading fastcore-1.5.29-py3-none-any.whl (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from fastai) (3.6.1)\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.9/dist-packages (from fastai) (22.3.1)\n",
      "Requirement already satisfied: torchvision>=0.11 in /usr/local/lib/python3.9/dist-packages (from fastai) (0.13.1+cu116)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from fastai) (5.4.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from fastai) (1.9.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from fastai) (23.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai) (66.1.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai) (3.3.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai) (0.10.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai) (4.64.1)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai) (8.1.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai) (2.0.7)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai) (1.23.4)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai) (0.4.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai) (1.0.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai) (1.9.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai) (3.0.12)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai) (2.4.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai) (3.0.8)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai) (3.1.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai) (1.0.9)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai) (0.10.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai) (2.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->fastai) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->fastai) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->fastai) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->fastai) (2.1.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch<2.3,>=1.10->fastai) (4.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->fastai) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->fastai) (1.0.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->fastai) (4.38.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->fastai) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->fastai) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->fastai) (1.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->fastai) (2022.7.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->fastai) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->fastai) (3.1.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from pathy>=0.3.5->spacy<4->fastai) (6.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->fastai) (1.14.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4->fastai) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4->fastai) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.5.0,>=0.3.0->spacy<4->fastai) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<4->fastai) (2.1.2)\n",
      "Installing collected packages: fastprogress, fastcore, fastdownload, fastai\n",
      "Successfully installed fastai-2.7.14 fastcore-1.5.29 fastdownload-0.0.7 fastprogress-1.0.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install langdetect\n",
    "!pip install fastai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c47220-e73b-4765-8ee4-dea54188bf3e",
   "metadata": {},
   "source": [
    "# 1. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb050d1a-94ba-4719-8933-170d2a1ddb13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-03T00:33:57.751303Z",
     "iopub.status.busy": "2024-02-03T00:33:57.751031Z",
     "iopub.status.idle": "2024-02-03T00:33:58.163348Z",
     "shell.execute_reply": "2024-02-03T00:33:58.162659Z",
     "shell.execute_reply.started": "2024-02-03T00:33:57.751281Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filename = 'bios.csv'\n",
    "\n",
    "texts = pd.read_csv(filename)['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adc22c3-7312-4114-a605-d0d489a8b1d6",
   "metadata": {},
   "source": [
    "# 2. Import pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6c3987e-d686-48ca-8dc6-e381b17edca9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-03T00:37:58.848900Z",
     "iopub.status.busy": "2024-02-03T00:37:58.848640Z",
     "iopub.status.idle": "2024-02-03T00:38:07.583336Z",
     "shell.execute_reply": "2024-02-03T00:38:07.576805Z",
     "shell.execute_reply.started": "2024-02-03T00:37:58.848881Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d50767bd9b94bc8b4b273baf1a340c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6925d6a6ae4e4bce9675d296f8eb98bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06b482497abd46a18c906b0c625e11fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63804912710444d9a17b4c8d6813aa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa68a0fe40524229890ba9717bfea4a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/523M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "import torch\n",
    "\n",
    "pretrained_weights = 'gpt2'\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(pretrained_weights)\n",
    "model = GPT2LMHeadModel.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b66ada1-2886-4fa7-8312-7b0df47fe999",
   "metadata": {},
   "source": [
    "# 3. Load data to fast.ai Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7544d1fc-a22d-447e-857d-bda7aa700662",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-03T00:51:13.491342Z",
     "iopub.status.busy": "2024-02-03T00:51:13.490694Z",
     "iopub.status.idle": "2024-02-03T00:51:14.324311Z",
     "shell.execute_reply": "2024-02-03T00:51:14.323603Z",
     "shell.execute_reply.started": "2024-02-03T00:51:13.491318Z"
    }
   },
   "outputs": [],
   "source": [
    "from fastai.text.all import *\n",
    "\n",
    "class TransformersTokenizer(Transform):\n",
    "    def __init__(self, tokenizer): self.tokenizer = tokenizer\n",
    "    def encodes(self, x): \n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        toks = self.tokenizer.tokenize(x)\n",
    "        return tensor(self.tokenizer.convert_tokens_to_ids(toks)).to(device).long()\n",
    "    def decodes(self, x): return TitledStr(self.tokenizer.decode(x.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61ce1580-8413-46aa-8ea6-6bf51584f5c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-03T00:40:43.121622Z",
     "iopub.status.busy": "2024-02-03T00:40:43.120840Z",
     "iopub.status.idle": "2024-02-03T00:40:43.126289Z",
     "shell.execute_reply": "2024-02-03T00:40:43.125647Z",
     "shell.execute_reply.started": "2024-02-03T00:40:43.121597Z"
    }
   },
   "outputs": [],
   "source": [
    "def splitter(model):\n",
    "    \"Split a GPT2 `model` in 3 groups for differential learning rates.\"\n",
    "    \n",
    "    # First layers group : decoder blocks from 0 to 3\n",
    "    modules = []\n",
    "    for i in range(4): modules.append(model.transformer.h[i])\n",
    "    groups = [nn.Sequential(*modules)]\n",
    "\n",
    "    # Second layers group : decoder blocks from 4 to 7\n",
    "    modules = []\n",
    "    for i in range(4,8,1): modules.append(model.transformer.h[i])\n",
    "    groups = L(groups + [nn.Sequential(*modules)])\n",
    "\n",
    "    # Third layers group : decoder blocks from 8 to 11\n",
    "    modules = []\n",
    "    for i in range(8,12,1): modules.append(model.transformer.h[i])\n",
    "    groups = L(groups + [nn.Sequential(*modules)])\n",
    "    \n",
    "    # Fourth layers group : embeddings matrices wte and wpe + LayerNorm at the model output\n",
    "    groups = L(groups + [nn.Sequential(model.transformer.wte,model.transformer.wpe,model.transformer.ln_f)])\n",
    "    \n",
    "    return groups.map(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd0b4386-2c27-46ae-afb0-41bdc5199398",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-03T00:51:16.081149Z",
     "iopub.status.busy": "2024-02-03T00:51:16.080556Z",
     "iopub.status.idle": "2024-02-03T00:51:16.084916Z",
     "shell.execute_reply": "2024-02-03T00:51:16.084196Z",
     "shell.execute_reply.started": "2024-02-03T00:51:16.081132Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace predictions with only its first element to allow fine-tuning\n",
    "class DropOutput(Callback):\n",
    "    def after_pred(self): self.learn.pred = self.pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a9b3257-01c4-44fa-abce-5873fc6b1459",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-03T00:52:27.135940Z",
     "iopub.status.busy": "2024-02-03T00:52:27.135675Z",
     "iopub.status.idle": "2024-02-03T00:52:27.140613Z",
     "shell.execute_reply": "2024-02-03T00:52:27.139969Z",
     "shell.execute_reply.started": "2024-02-03T00:52:27.135921Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_learner(train_pct=0.7):\n",
    "    \n",
    "    '''Function that load data into fast.ai and create a fast.ai learner using the data.'''\n",
    "    \n",
    "    # Transform texts into token : id mappings\n",
    "    l = len(texts)\n",
    "    train_len = int(l * train_pct)\n",
    "    splits = [range_of(train_len), list(range(train_len, l))]\n",
    "    tls = TfmdLists(texts, TransformersTokenizer(tokenizer), splits=splits, dl_type=LMDataLoader)\n",
    "    \n",
    "    # Create a dataloader object that contains attributes used in training loop\n",
    "    bs,sl = 4,256 # batch_size, sequence_length\n",
    "    dls = tls.dataloaders(bs=bs, seq_len=sl)\n",
    "    \n",
    "    # Create a learner for our use\n",
    "    learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), \n",
    "                    splitter = splitter, cbs=[DropOutput], \n",
    "                    metrics=[accuracy, Perplexity()]).to_fp16()\n",
    "    \n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3956f91-7b09-430b-90cc-8813829e9793",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-03T00:52:29.033615Z",
     "iopub.status.busy": "2024-02-03T00:52:29.032960Z",
     "iopub.status.idle": "2024-02-03T00:52:37.624858Z",
     "shell.execute_reply": "2024-02-03T00:52:37.624142Z",
     "shell.execute_reply.started": "2024-02-03T00:52:29.033594Z"
    }
   },
   "outputs": [],
   "source": [
    "learn = get_learner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3ac1c86-2fcc-4f43-a9d7-9caba447cb2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-03T03:29:19.528829Z",
     "iopub.status.busy": "2024-02-03T03:29:19.528239Z",
     "iopub.status.idle": "2024-02-03T03:29:19.532544Z",
     "shell.execute_reply": "2024-02-03T03:29:19.531985Z",
     "shell.execute_reply.started": "2024-02-03T03:29:19.528804Z"
    }
   },
   "outputs": [],
   "source": [
    "def initial_fine_tune(learn):\n",
    "    \n",
    "    '''Function that applies 1 epoch to frozen pre-trained model.'''\n",
    "    \n",
    "    # Print metrics without fine-tuning\n",
    "    learn.validate()\n",
    "    \n",
    "    # Freeze pre-trained model\n",
    "    learn.freeze()\n",
    "    \n",
    "    # Fine-tune once\n",
    "    lr_rec = learn.lr_find().valley\n",
    "    lr = lr_rec * 1/3\n",
    "    learn.fit_one_cycle(1, lr)\n",
    "    \n",
    "    learn.recorder.plot_loss()\n",
    "    \n",
    "    learn.save(\"1epoch\")\n",
    "    \n",
    "    return learn, lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "573bbecb-f8d0-4799-acfa-a7d11278a8bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-03T03:31:03.853062Z",
     "iopub.status.busy": "2024-02-03T03:31:03.852192Z",
     "iopub.status.idle": "2024-02-03T03:31:03.857153Z",
     "shell.execute_reply": "2024-02-03T03:31:03.856482Z",
     "shell.execute_reply.started": "2024-02-03T03:31:03.853029Z"
    }
   },
   "outputs": [],
   "source": [
    "def fine_tune_10epoch(learn, lr):\n",
    "    \n",
    "    '''Function that applies 10 epoch to frozen pre-trained model.\n",
    "    Use lr from `initial_fine_tune()`'''\n",
    "    \n",
    "    # Freeze pre-trained model\n",
    "    learn.freeze()\n",
    "    \n",
    "    # Fine-tune for 10 epochs\n",
    "    lr *= 1/10\n",
    "    learn.fit_one_cycle(10, lr)\n",
    "    \n",
    "    # Save\n",
    "    learn.save(\"10epoch\")\n",
    "    \n",
    "    return learn, lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fcf0f1-256d-4936-a769-3b0688f7ec54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_unfreeze_2_layers(learn, lr):\n",
    "    \n",
    "    '''Function that applies 1 epoch to model that have the last 2 layers unfrozen.\n",
    "    Use lr from `initial_fine_tune()`'''\n",
    "    \n",
    "    learn.freeze_to(-2)\n",
    "    \n",
    "    lr *= 1/2\n",
    "    learn.fit_one_cycle(1, slice(lr/(2.6**4),lr))\n",
    "    \n",
    "    learn.recorder.plot_loss()\n",
    "    \n",
    "    learn.save(\"unfreeze_2_layers\")\n",
    "    \n",
    "    return learn, lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7e26aa-e150-4c05-9093-c2132d8f5e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_unfreeze_3_layers(learn, lr):\n",
    "    \n",
    "    '''Function that applies 1 epoch to model that have the last 3 layers unfrozen.\n",
    "    Use lr from `fine_tune_unfreeze_2_layers()`'''\n",
    "    \n",
    "    learn.freeze_to(-3)\n",
    "    \n",
    "    lr *= 1/2\n",
    "    learn.fit_one_cycle(1, slice(lr/(2.6**4),lr))\n",
    "    \n",
    "    learn.recorder.plot_loss()\n",
    "    \n",
    "    learn.save(\"unfreeze_3_layers\")\n",
    "    \n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e255addb-46f5-45f1-a6e4-ce59a27d3443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_unfreeze(learn, lr):\n",
    "    \n",
    "    '''Function that applies 1 epoch to model that have all layers unfrozen.\n",
    "    Use lr from `fine_tune_unfreeze_2_layers()`'''\n",
    "    \n",
    "    learn.unfreeze()\n",
    "    \n",
    "    lr *= 1/10\n",
    "    learn.fit_one_cycle(1, slice(lr/(2.6**4),lr))\n",
    "    \n",
    "    learn.recorder.plot_loss()\n",
    "    \n",
    "    learn.save(\"fine-tuned\")\n",
    "    \n",
    "    return learn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
